#!/usr/bin/env python3
"""
Script para capturar dados da vers√£o 99090886-7f43-45c9-bfe4-ec6eddd6cde0 do Directus
e salvar como fixture para testes reproduz√≠veis.

Uso:
    cd versiona-ai/tests/sample/versao-99090886
    python capture_fixture.py
"""

import json
import sys
from pathlib import Path

import requests

# Adicionar o diret√≥rio raiz ao path
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# Configura√ß√£o
VERSAO_ID = "99090886-7f43-45c9-bfe4-ec6eddd6cde0"
OUTPUT_DIR = Path(__file__).parent


def capture_data():
    """Captura todos os dados necess√°rios do Directus."""
    print(f"üîç Capturando dados da vers√£o {VERSAO_ID}...")

    # 1. Processar vers√£o para obter resultado completo
    print("üì• Processando vers√£o (simula POST /api/process)...")
    response = requests.post(
        "http://localhost:8001/api/process",
        json={"versao_id": VERSAO_ID},
        headers={"Content-Type": "application/json"},
    )

    if response.status_code != 200:
        print(f"‚ùå Erro ao processar vers√£o: {response.status_code}")
        print(response.text)
        return False

    result = response.json()

    # Salvar resultado completo do processamento
    with open(OUTPUT_DIR / "resultado_processamento.json", "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    print("‚úÖ Resultado do processamento salvo: resultado_processamento.json")

    # 2. Extrair m√©tricas de vincula√ß√£o
    metrics = result.get("vinculacao_metrics", {})
    with open(OUTPUT_DIR / "vinculacao_metrics.json", "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    print("‚úÖ M√©tricas de vincula√ß√£o salvas: vinculacao_metrics.json")

    # 3. Extrair modifica√ß√µes detalhadas
    modificacoes = result.get("modificacoes", [])
    with open(OUTPUT_DIR / "modificacoes_processadas.json", "w", encoding="utf-8") as f:
        json.dump(modificacoes, f, indent=2, ensure_ascii=False)
    print(
        f"‚úÖ Modifica√ß√µes processadas salvas ({len(modificacoes)} items): modificacoes_processadas.json"
    )

    # 4. Criar resumo para testes
    resumo = {
        "versao_id": VERSAO_ID,
        "data_captura": result.get("created_at"),
        "metricas": {
            "total_modificacoes": len(modificacoes),
            "vinculadas": metrics.get("vinculadas", 0),
            "revisao_manual": metrics.get("revisao_manual", 0),
            "nao_vinculadas": metrics.get("nao_vinculadas", 0),
            "taxa_sucesso": metrics.get("taxa_sucesso", 0),
            "taxa_cobertura": metrics.get("taxa_cobertura", 0),
            "tags_mapeadas": metrics.get("tags_mapeadas", 0),
        },
        "qualidade": {
            "similaridade": metrics.get("similaridade", 0),
            "metodo_usado": metrics.get("metodo_usado", ""),
        },
        "arquivos_gerados": [
            "resultado_processamento.json",
            "vinculacao_metrics.json",
            "modificacoes_processadas.json",
            "test_expectations.json",
        ],
    }

    with open(OUTPUT_DIR / "fixture_summary.json", "w", encoding="utf-8") as f:
        json.dump(resumo, f, indent=2, ensure_ascii=False)

    # 5. Criar expectativas para testes
    expectations = {
        "description": "Expectativas m√≠nimas para teste de regress√£o da vers√£o 99090886",
        "versao_id": VERSAO_ID,
        "min_vinculacao_taxa": 40.0,  # M√≠nimo de 40% de vincula√ß√£o
        "min_cobertura_taxa": 45.0,  # M√≠nimo de 45% de cobertura
        "min_similaridade": 0.90,  # M√≠nimo de 90% de similaridade
        "metodo_esperado": "conteudo",  # Deve usar m√©todo conte√∫do
        "baseline": {
            "vinculadas": metrics.get("vinculadas", 0),
            "revisao_manual": metrics.get("revisao_manual", 0),
            "nao_vinculadas": metrics.get("nao_vinculadas", 0),
            "taxa_sucesso": metrics.get("taxa_sucesso", 0),
            "taxa_cobertura": metrics.get("taxa_cobertura", 0),
        },
        "note": "Estes valores s√£o baseados no resultado do commit e4cc120 (conte√∫do + fuzzy matching)",
    }

    with open(OUTPUT_DIR / "test_expectations.json", "w", encoding="utf-8") as f:
        json.dump(expectations, f, indent=2, ensure_ascii=False)
    print("‚úÖ Expectativas de teste salvas: test_expectations.json")

    # 6. Criar README
    readme_content = f"""# Fixture: Vers√£o 99090886-7f43-45c9-bfe4-ec6eddd6cde0

## Descri√ß√£o

Esta fixture cont√©m dados reais capturados do Directus para a vers√£o `{VERSAO_ID}`.
Os dados foram capturados ap√≥s a implementa√ß√£o do m√©todo de conte√∫do + fuzzy matching (commit e4cc120).

## Arquivos

- `resultado_processamento.json`: Resultado completo do processamento da vers√£o
- `vinculacao_metrics.json`: M√©tricas detalhadas de vincula√ß√£o
- `modificacoes_processadas.json`: Lista completa de modifica√ß√µes com vincula√ß√µes
- `test_expectations.json`: Expectativas m√≠nimas para testes de regress√£o
- `fixture_summary.json`: Resumo da captura
- `README.md`: Este arquivo

## M√©tricas Capturadas

- **Total de modifica√ß√µes**: {len(modificacoes)}
- **Vinculadas**: {metrics.get("vinculadas", 0)} ({metrics.get("taxa_sucesso", 0):.1f}%)
- **Revis√£o manual**: {metrics.get("revisao_manual", 0)} ({metrics.get("revisao_manual", 0) / len(modificacoes) * 100:.1f}%)
- **N√£o vinculadas**: {metrics.get("nao_vinculadas", 0)} ({metrics.get("nao_vinculadas", 0) / len(modificacoes) * 100:.1f}%)
- **Taxa de cobertura**: {metrics.get("taxa_cobertura", 0):.1f}%
- **Similaridade**: {metrics.get("similaridade", 0):.2%}
- **M√©todo usado**: {metrics.get("metodo_usado", "N/A")}

## Uso em Testes

```python
import json
from pathlib import Path

# Carregar fixture
fixture_dir = Path(__file__).parent / "versao-99090886"
with open(fixture_dir / "test_expectations.json") as f:
    expectations = json.load(f)

# Executar teste
result = process_versao(expectations["versao_id"])

# Validar contra expectativas
assert result["vinculacao_metrics"]["taxa_sucesso"] >= expectations["min_vinculacao_taxa"]
assert result["vinculacao_metrics"]["taxa_cobertura"] >= expectations["min_cobertura_taxa"]
assert result["vinculacao_metrics"]["similaridade"] >= expectations["min_similaridade"]
```

## Atualiza√ß√£o

Para atualizar esta fixture:

```bash
cd versiona-ai/tests/sample/versao-99090886
python capture_fixture.py
```

## Data da Captura

{result.get("created_at", "N/A")}
"""

    with open(OUTPUT_DIR / "README.md", "w", encoding="utf-8") as f:
        f.write(readme_content)
    print("‚úÖ README criado: README.md")

    print("\n" + "=" * 60)
    print("‚úÖ CAPTURA COMPLETA!")
    print("=" * 60)
    print("üìä Resumo:")
    print(f"   - Vers√£o: {VERSAO_ID}")
    print(f"   - Modifica√ß√µes: {len(modificacoes)}")
    print(
        f"   - Vinculadas: {metrics.get('vinculadas', 0)} ({metrics.get('taxa_sucesso', 0):.1f}%)"
    )
    print(f"   - Cobertura: {metrics.get('taxa_cobertura', 0):.1f}%")
    print(f"   - Similaridade: {metrics.get('similaridade', 0):.2%}")
    print(f"   - M√©todo: {metrics.get('metodo_usado', 'N/A')}")
    print(f"\nüìÅ Arquivos salvos em: {OUTPUT_DIR}")
    print("=" * 60)

    return True


if __name__ == "__main__":
    success = capture_data()
    sys.exit(0 if success else 1)
