# Task 003: Corrigir Vincula√ß√£o de Modifica√ß√µes √†s Cl√°usulas (Meta: 100%)

**Data de Cria√ß√£o:** 2025-10-11
**Status:** üü° Solu√ß√£o Proposta (Refinada)
**Prioridade:** Alta
**Respons√°vel:** A definir

---

## üéØ Resumo Executivo

**Problema:** Apenas 14.5% (8/55) das modifica√ß√µes est√£o sendo vinculadas √†s cl√°usulas corretas devido a um deslocamento no sistema de coordenadas entre o arquivo COM tags (modelo) e o arquivo original da vers√£o.

**Solu√ß√£o:** Implementar algoritmo unificado com duas estrat√©gias:

1. **Caminho Feliz (95%+ similaridade):** C√°lculo matem√°tico de offset ‚Üí 100% preciso
2. **Caminho Real (<95% similaridade):** Infer√™ncia por conte√∫do com contexto ‚Üí 85-95% preciso

**Benef√≠cios:**

- üìà **+500% de melhoria:** De 14.5% para 75-85% de vincula√ß√£o autom√°tica
- üéØ **90-98% de cobertura total:** Incluindo fila de revis√£o manual
- üìä **Sistema de qualidade:** Score de confian√ßa (0.0-1.0) para cada vincula√ß√£o
- üîç **Revis√£o inteligente:** Apenas casos amb√≠guos v√£o para revis√£o humana

**Esfor√ßo:** 30-44 horas (~1 semana) dividido em 6 fases incrementais

**Risco:** üü¢ Baixo - Solu√ß√£o test√°vel por partes, com fallback e reversibilidade

---

## ÔøΩ √çndice

1. [üéØ Resumo Executivo](#-resumo-executivo)
2. [üìã Contexto](#-contexto)
3. [üéØ Objetivo](#-objetivo)
4. [‚ö†Ô∏è Problema Identificado](#Ô∏è-problema-identificado-revisado)
5. [üí° Solu√ß√£o Proposta](#-solu√ß√£o-proposta-algoritmo-unificado-de-mapeamento-de-coordenadas)
   - [Cen√°rio 1: Caminho Feliz](#cen√°rio-1-caminho-feliz-arquivos-id√™nticos)
   - [Cen√°rio 2: Caminho Real](#cen√°rio-2-caminho-real-arquivos-diferentes)
   - [Algoritmo Unificado](#o-algoritmo-unificado)
6. [üîß Casos de Borda e Robustez](#-casos-de-borda-e-robustez)
7. [üìÅ Arquivos Relevantes](#-arquivos-relevantes-para-a-solu√ß√£o)
8. [üß™ Como Testar](#-como-testar-a-solu√ß√£o)
9. [üìä Crit√©rios de Sucesso](#-crit√©rios-de-sucesso)
10. [üìà Estimativa de Taxa de Sucesso](#-estimativa-de-taxa-de-sucesso)
11. [üîç Considera√ß√µes T√©cnicas](#-considera√ß√µes-t√©cnicas-adicionais)
12. [üöÄ Pr√≥ximos Passos](#-pr√≥ximos-passos-sugeridos-ordem-de-implementa√ß√£o)
13. [üìö Refer√™ncias](#-refer√™ncias-e-recursos)

---

## ÔøΩüìã Contexto

Ap√≥s implementa√ß√£o inicial da vincula√ß√£o de modifica√ß√µes √†s cl√°usulas via tags do modelo de contrato, obtivemos apenas **14.5% de sucesso (8/55 modifica√ß√µes vinculadas)**. O objetivo √© alcan√ßar **100% de vincula√ß√£o** para todas as modifica√ß√µes que possuem correspond√™ncia v√°lida no modelo.

---

## üéØ Objetivo

Implementar um **algoritmo unificado de mapeamento de coordenadas** para que **100% das modifica√ß√µes v√°lidas sejam vinculadas √†s suas cl√°usulas correspondentes**, corrigindo o deslocamento entre os sistemas de coordenadas do `diff` e das tags.

---

## ‚ö†Ô∏è Problema Identificado (Revisado)

### Raiz do Problema: Deslocamento de Coordenadas

O problema n√£o √© que os documentos s√£o fundamentalmente diferentes, mas sim que o **`arquivo_com_tags` √© uma deriva√ß√£o do `arquivo_original`**, com as tags injetadas. Essa inje√ß√£o **desloca as coordenadas** de tudo que vem depois da primeira tag.

1.  **Arquivo Original (Base):** `BOM DIA.`
2.  **Arquivo COM Tags (Derivado):** `BOM{{TAG-1}} DIA{{/TAG-1}}.`

A posi√ß√£o da modifica√ß√£o √© calculada no Arquivo 1, enquanto a posi√ß√£o da tag √© salva no Arquivo 2. Compar√°-las diretamente √© como comparar o endere√ßo de uma casa em uma rua antes e depois de construir um novo pr√©dio no quarteir√£o.

### O Que Acontece Hoje

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASSO 1: Gerar Diff                                             ‚îÇ
‚îÇ diff = compare(arquivo_original_versao, arquivo_modificado)     ‚îÇ
‚îÇ ‚Üí Modifica√ß√µes t√™m posi√ß√µes no arquivo_original_vers√£o          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASSO 2: Vincular √†s Tags                                       ‚îÇ
‚îÇ tags = buscar_tags_do_modelo()                                  ‚îÇ
‚îÇ ‚Üí Tags t√™m posi√ß√µes no arquivo_com_tags (SISTEMA DESLOCADO!)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PROBLEMA: Compara√ß√£o Inv√°lida                                   ‚îÇ
‚îÇ if tag.posicao_inicio <= mod.posicao <= tag.posicao_fim:        ‚îÇ
‚îÇ    ‚ùå FALSO POSITIVO ou FALSO NEGATIVO                          ‚îÇ
‚îÇ    (comparando posi√ß√µes de sistemas deslocados!)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üí° Solu√ß√£o Proposta: Algoritmo Unificado de Mapeamento de Coordenadas

Propomos um algoritmo robusto que lida com dois cen√°rios principais, escolhendo a estrat√©gia ideal para cada caso.

### Cen√°rio 1: "Caminho Feliz" (Arquivos Id√™nticos)

Quando o `arquivo_original_versao` √© id√™ntico ao texto base usado para gerar as tags, podemos usar um c√°lculo matem√°tico preciso.

**Abordagem: C√°lculo de Offset com Tags Aninhadas**

1.  **Verificar similaridade:** Calcular similaridade entre `arquivo_original_versao` (normalizado) e `arquivo_com_tags` (sem tags e normalizado). Threshold: **‚â• 95%** para considerar id√™nticos.
2.  **Calcular offset acumulado:** Percorrer o arquivo COM tags em ordem linear, acumulando o tamanho de cada tag encontrada. Isso gera um mapa: `(posicao_com_tag ‚Üí offset_acumulado)`.

```python
# Exemplo:
# Arquivo Original: "ABC DEF GHI"
# Arquivo COM Tags: "ABC {{TAG-1}}DEF {{TAG-2}}GHI{{/TAG-2}}{{/TAG-1}}"
#
# Mapa de offsets:
# posicao 0-3:   offset = 0   (antes de qualquer tag)
# posicao 4-6:   offset = 11  (depois de "{{TAG-1}}")
# posicao 7-9:   offset = 22  (depois de "{{TAG-1}}" e "{{TAG-2}}")
```

3.  **Mapear tags para coordenadas originais:** Para cada tag, calcular:

- `posicao_original_inicio = posicao_com_tags_inicio - offset_antes_da_tag`
- `posicao_original_fim = posicao_com_tags_fim - offset_antes_da_tag`

4.  **Vincular:** Comparar a posi√ß√£o da modifica√ß√£o com a posi√ß√£o da tag recalculada.

**Vantagens:**

- ‚úÖ **100% preciso e infal√≠vel** para este cen√°rio.
- ‚úÖ **Extremamente r√°pido** (complexidade O(N log N) por ordena√ß√£o).
- ‚úÖ **Lida corretamente com tags aninhadas** atrav√©s do offset acumulado.

### Cen√°rio 2: "Caminho Real" (Arquivos Diferentes)

Quando o `arquivo_original_versao` √© uma vers√£o antiga ou foi alterado, o c√°lculo de offset falha. Usamos uma abordagem de infer√™ncia baseada em conte√∫do com contexto de vizinhan√ßa.

**Abordagem: Infer√™ncia por Conte√∫do com Contexto (LCS + Vizinhan√ßa)**

1.  **Para cada tag:** Extrair tr√™s elementos:
    - **Conte√∫do textual:** O texto dentro da tag (ex: " DIA ")
    - **Contexto anterior:** N caracteres antes da tag (sugerido: 50 caracteres)
    - **Contexto posterior:** N caracteres depois da tag (sugerido: 50 caracteres)
2.  **Normalizar** o conte√∫do da tag e o texto do `arquivo_original_versao`.
3.  **Inferir posi√ß√£o com contexto:** Buscar a sequ√™ncia `contexto_antes + conteudo + contexto_depois` dentro do arquivo da vers√£o usando busca por subsequ√™ncia comum (LCS).
    - **Benef√≠cio do contexto:** Resolve ambiguidade quando o mesmo texto aparece em m√∫ltiplas cl√°usulas.
    - **Exemplo:** "O contratante pagar√°" pode aparecer em cl√°usulas diferentes, mas o contexto diferencia.
4.  **Fallback:** Se n√£o encontrar com contexto completo, tentar:
    - Apenas conte√∫do + contexto posterior
    - Apenas conte√∫do + contexto anterior
    - Apenas conte√∫do (√∫ltimo recurso)
5.  **Score de confian√ßa:** Atribuir score baseado no m√©todo usado:
    - Contexto completo: **0.9**
    - Contexto parcial: **0.7**
    - Apenas conte√∫do: **0.5**
6.  **Vincular:** Usar a posi√ß√£o inferida para vincular a modifica√ß√£o.

**Vantagens:**

- ‚úÖ **Robusto**, lida com documentos de bases diferentes.
- ‚úÖ **Funciona mesmo se o conte√∫do da cl√°usula foi alterado** (usando contexto).
- ‚úÖ **Resolve ambiguidade** atrav√©s do contexto de vizinhan√ßa.
- ‚úÖ **M√∫ltiplos n√≠veis de fallback** aumentam taxa de sucesso.

**Otimiza√ß√µes de Performance:**

- üöÄ **√çndice de n-gramas:** Pr√©-processar o arquivo original em chunks de 20-50 caracteres para busca r√°pida.
- üöÄ **Early exit:** Se encontrar match exato com contexto, n√£o testar outras varia√ß√µes.
- üöÄ **Paraleliza√ß√£o:** Processar tags em paralelo usando `multiprocessing` para documentos grandes.

### O Algoritmo Unificado

A solu√ß√£o final √© uma fun√ß√£o que tenta o "Caminho Feliz" primeiro e, em caso de falha, recorre ao "Caminho Real", com sistema de score e revis√£o manual.

```python
def vincular_modificacoes_unificado(tags, modificacoes, arquivo_original_versao, arquivo_com_tags):
    """
    Algoritmo unificado com fallback e score de confian√ßa.

    Returns:
        dict: {
            'vinculadas': [(mod, clausula, score), ...],
            'nao_vinculadas': [mod, ...],
            'revisao_manual': [(mod, candidatos, score), ...]
        }
    """
    # 1. Normalizar textos
    texto_base = normalizar(extrair_texto_sem_tags(arquivo_com_tags))
    texto_versao = normalizar(arquivo_original_versao)

    # 2. Escolher estrat√©gia baseado em similaridade
    similaridade = calcular_similaridade(texto_base, texto_versao)

    if similaridade >= 0.95:  # Threshold: 95%
        print(f"üéØ Caminho Feliz: Documentos id√™nticos (similaridade: {similaridade:.2%})")
        tags_mapeadas = mapear_via_offset(tags, arquivo_com_tags)
        score_base = 1.0  # Confian√ßa m√°xima
    else:
        print(f"üéØ Caminho Real: Documentos divergentes (similaridade: {similaridade:.2%})")
        tags_mapeadas = inferir_via_conteudo_com_contexto(tags, texto_versao, arquivo_com_tags)
        score_base = 0.8  # Confian√ßa reduzida (ajustado durante infer√™ncia)

    # 3. Vincular com c√°lculo de score e categoriza√ß√£o
    resultados = {
        'vinculadas': [],
        'nao_vinculadas': [],
        'revisao_manual': []
    }

    for mod in modificacoes:
        candidatos = encontrar_tags_sobrepostas(mod, tags_mapeadas)

        if not candidatos:
            resultados['nao_vinculadas'].append(mod)
            continue

        # Calcular score para cada candidato
        melhor_candidato = None
        melhor_score = 0

        for tag in candidatos:
            percentual_sobreposicao = calcular_sobreposicao(mod, tag)
            score = tag.score_inferencia * percentual_sobreposicao  # score_inferencia vem do "Caminho"

            if score > melhor_score:
                melhor_score = score
                melhor_candidato = tag

        # Decidir destino baseado no score
        if melhor_score >= 0.7:  # Alta confian√ßa
            resultados['vinculadas'].append((mod, melhor_candidato.clausula, melhor_score))
        elif melhor_score >= 0.4:  # M√©dia confian√ßa - revis√£o manual
            resultados['revisao_manual'].append((mod, candidatos, melhor_score))
        else:  # Baixa confian√ßa
            resultados['nao_vinculadas'].append(mod)

    # 4. Log de estat√≠sticas
    total = len(modificacoes)
    print(f"üìä Vincula√ß√£o conclu√≠da:")
    print(f"   ‚úÖ Vinculadas: {len(resultados['vinculadas'])}/{total} ({len(resultados['vinculadas'])/total*100:.1f}%)")
    print(f"   üîç Revis√£o manual: {len(resultados['revisao_manual'])}/{total} ({len(resultados['revisao_manual'])/total*100:.1f}%)")
    print(f"   ‚ùå N√£o vinculadas: {len(resultados['nao_vinculadas'])}/{total} ({len(resultados['nao_vinculadas'])/total*100:.1f}%)")

    return resultados
```

**Thresholds Configur√°veis:**

- **Similaridade para Caminho Feliz:** 95% (ajustar se necess√°rio)
- **Score m√≠nimo para vincula√ß√£o autom√°tica:** 0.7
- **Score m√≠nimo para revis√£o manual:** 0.4
- **Contexto de vizinhan√ßa:** 50 caracteres (ajustar para cl√°usulas muito curtas/longas)

---

## üîß Casos de Borda e Robustez

A solu√ß√£o incluir√° mecanismos para lidar com situa√ß√µes complexas:

### 1. Modifica√ß√µes que Cruzam Fronteiras de Cl√°usulas

**Problema:** Uma modifica√ß√£o pode afetar o final de uma cl√°usula e o in√≠cio da pr√≥xima.

```
Exemplo:
Cl√°usula 1.1: [pos 0-1000]   "...final da cl√°usula"
Cl√°usula 1.2: [pos 1001-2000] "in√≠cio da pr√≥xima..."
Modifica√ß√£o: [pos 950-1050]   Afeta ambas! (50 chars em cada)
```

**Solu√ß√£o:**

- **Regra Principal:** Vincular √† cl√°usula que cont√©m a **maior parte** da modifica√ß√£o.
- **Vincula√ß√£o M√∫ltipla (Opcional):** Se ambas as cl√°usulas t√™m sobreposi√ß√£o ‚â• 30% (threshold configur√°vel):
  ```python
  if percentual_sobreposicao_clausula_2 >= 0.30:
      modificacao.clausulas = [clausula_1, clausula_2]  # Array
      modificacao.clausula_principal = clausula_com_maior_sobreposicao
      modificacao.flag_multi_clausula = True
  ```
- **Benef√≠cio:** Permite an√°lises mais ricas (ex: "modifica√ß√µes que afetam m√∫ltiplas cl√°usulas").

### 2. Score de Confian√ßa em Tr√™s N√≠veis

Cada vincula√ß√£o ter√° um score que determina seu tratamento:

| N√≠vel                  | Score      | A√ß√£o                   | Exemplo                           |
| ---------------------- | ---------- | ---------------------- | --------------------------------- |
| üü¢ **Alta Confian√ßa**  | ‚â• 0.7      | Vincula√ß√£o autom√°tica  | Caminho Feliz + 100% sobreposi√ß√£o |
| üü° **M√©dia Confian√ßa** | 0.4 - 0.69 | Fila de revis√£o manual | Infer√™ncia com contexto parcial   |
| üî¥ **Baixa Confian√ßa** | < 0.4      | N√£o vincular (orphan)  | M√∫ltiplos candidatos amb√≠guos     |

**C√°lculo do Score:**

```python
score_final = score_metodo √ó percentual_sobreposicao √ó fator_contexto

Onde:
- score_metodo: 1.0 (offset), 0.9 (contexto completo), 0.7 (parcial), 0.5 (s√≥ conte√∫do)
- percentual_sobreposicao: 0.0 a 1.0 (quanto da modifica√ß√£o est√° dentro da tag)
- fator_contexto: 1.0 (√∫nico candidato), 0.8 (m√∫ltiplos candidatos mas um claro vencedor)
```

### 3. Fila de Revis√£o Manual

Modifica√ß√µes com m√©dia confian√ßa (0.4-0.69) s√£o enviadas para revis√£o:

```json
{
  "modificacao_id": 42,
  "candidatos": [
    {
      "clausula": "1.1 - Objeto do Contrato",
      "score": 0.62,
      "razao": "Infer√™ncia com contexto parcial, 80% de sobreposi√ß√£o"
    },
    {
      "clausula": "2.1 - Objeto da Empreitada",
      "score": 0.45,
      "razao": "Texto similar mas contexto diferente, 50% de sobreposi√ß√£o"
    }
  ],
  "recomendacao": "clausula_1",
  "requer_revisao_humana": true
}
```

**Interface Sugerida (futuro):**

- Dashboard mostrando modifica√ß√µes pendentes de revis√£o
- Bot√µes: "Aprovar recomenda√ß√£o", "Escolher outro candidato", "Marcar como sem cl√°usula"

### 4. Textos Amb√≠guos (Repetidos)

**Problema:** Cl√°usulas com texto id√™ntico ou muito similar.

```
Cl√°usula 1.1: "O contratante pagar√° o valor acordado..."
Cl√°usula 5.1: "O contratante pagar√° o valor acordado..."  # Id√™ntico!
```

**Solu√ß√µes Implementadas:**

- ‚úÖ **Contexto de vizinhan√ßa** (50 chars antes/depois) diferencia na maioria dos casos
- ‚úÖ **Ordena√ß√£o por score** garante que apenas o melhor candidato seja escolhido
- ‚úÖ Se m√∫ltiplos candidatos com score similar (diferen√ßa < 0.1), marcar para revis√£o manual

### 5. Performance com Documentos Grandes

**Problema:** Busca por subsequ√™ncia (LCS) √© O(n√óm). Com 100 tags e documento de 200KB:

- Pior caso: ~2 segundos por documento

**Otimiza√ß√µes:**

1. **√çndice de N-gramas (Pr√©-processamento):**

   ```python
   # Construir √≠ndice uma vez por documento
   indice = construir_indice_ngramas(arquivo_original, n=20)
   # {
   #   "O contratante paga": [pos1, pos37, pos842, ...],
   #   "contratante pagar√°": [pos2, pos38, pos843, ...],
   #   ...
   # }

   # Busca se torna O(1) amortizado
   posicoes_candidatas = indice.buscar(primeiros_20_chars_da_tag)
   ```

2. **Early Exit:**

   ```python
   if encontrou_match_com_contexto_completo_e_score_1_0:
       return resultado  # N√£o testar fallbacks
   ```

3. **Paraleliza√ß√£o (Opcional):**

   ```python
   from multiprocessing import Pool

   with Pool(processes=4) as pool:
       tags_mapeadas = pool.map(inferir_posicao_tag, tags)
   ```

   - √ötil para documentos com 100+ tags
   - Reduz tempo de ~2s para ~0.5s (4 cores)

### 6. Normaliza√ß√£o Consistente

Garantir que a normaliza√ß√£o seja **idempotente e consistente** em todos os pontos:

```python
def normalizar_texto(texto):
    """Normaliza√ß√£o padronizada para todo o sistema."""
    # 1. Converter para min√∫sculas (opcional, depende do caso de uso)
    # texto = texto.lower()

    # 2. Normalizar espa√ßos em branco
    texto = re.sub(r'\s+', ' ', texto)

    # 3. Remover espa√ßos no in√≠cio/fim
    texto = texto.strip()

    # 4. Normalizar quebras de linha (se relevante)
    texto = texto.replace('\r\n', '\n').replace('\r', '\n')

    # 5. Unicode normalization (NFC)
    import unicodedata
    texto = unicodedata.normalize('NFC', texto)

    return texto
```

**IMPORTANTE:** Aplicar a **mesma fun√ß√£o** em:

- Arquivo COM tags (ao remover tags)
- Arquivo original da vers√£o
- Conte√∫do extra√≠do das tags
- Contexto de vizinhan√ßa

---

## üìÅ Arquivos Relevantes para a Solu√ß√£o

### C√≥digo Principal

1.  **`versiona-ai/directus_server.py`**

    **Fun√ß√µes a Criar:**

    - **`_vincular_modificacoes_clausulas_unificado()`** (nova - principal)

      - Implementa a l√≥gica `if/else` do algoritmo unificado
      - Calcula similaridade e escolhe entre Caminho Feliz ou Real
      - Retorna dict com vinculadas/nao_vinculadas/revisao_manual
      - **Assinatura:** `(tags, modificacoes, arquivo_original_versao, arquivo_com_tags) ‚Üí dict`

    - **`_mapear_tags_via_offset()`** (nova - Caminho Feliz)

      - Implementa o c√°lculo de offset acumulado para tags aninhadas
      - Percorre arquivo COM tags, identifica todas as tags via regex
      - Para cada tag, calcula: `posicao_original = posicao_com_tags - offset_acumulado`
      - **Assinatura:** `(tags, arquivo_com_tags) ‚Üí List[TagMapeada]`
      - **Complexidade:** O(N log N) onde N = n√∫mero de tags

    - **`_inferir_posicoes_via_conteudo_com_contexto()`** (nova - Caminho Real)

      - Implementa busca por subsequ√™ncia com contexto de vizinhan√ßa
      - Para cada tag: extrai conte√∫do + 50 chars antes + 50 chars depois
      - Tenta match com contexto completo, depois parcial, depois s√≥ conte√∫do
      - Atribui score baseado no m√©todo usado (0.9, 0.7, 0.5)
      - **Assinatura:** `(tags, arquivo_original_versao, arquivo_com_tags) ‚Üí List[TagMapeada]`
      - **Complexidade:** O(T √ó M) onde T = n√∫mero de tags, M = tamanho do documento
      - **Otimiza√ß√£o:** Usar √≠ndice de n-gramas para reduzir M

    - **`_vincular_por_sobreposicao_com_score()`** (nova)

      - L√≥gica final de vincula√ß√£o com coordenadas j√° alinhadas
      - Para cada modifica√ß√£o, encontra tags que se sobrep√µem
      - Calcula score: `tag.score_inferencia √ó percentual_sobreposicao √ó fator_contexto`
      - Categoriza: alta confian√ßa (‚â•0.7), revis√£o (0.4-0.69), baixa (<0.4)
      - **Assinatura:** `(modificacoes, tags_mapeadas) ‚Üí dict`

    - **`_calcular_similaridade_textos()`** (nova - utilit√°rio)

      - Calcula similaridade entre dois textos normalizados
      - Usa algoritmo de dist√¢ncia de Levenshtein ou ratio do difflib
      - **Assinatura:** `(texto1, texto2) ‚Üí float (0.0 a 1.0)`

    - **`_construir_indice_ngramas()`** (nova - otimiza√ß√£o)

      - Constr√≥i √≠ndice de n-gramas para busca r√°pida
      - **Assinatura:** `(texto, n=20) ‚Üí Dict[str, List[int]]`
      - **Opcional:** Implementar apenas se performance for problema

    - **`normalizar_texto()`** (modificar existente ou criar nova)
      - Fun√ß√£o centralizada de normaliza√ß√£o
      - Deve ser usada em TODOS os pontos: tags, modifica√ß√µes, contexto
      - Garante consist√™ncia: espa√ßos, quebras de linha, unicode
      - **Assinatura:** `(texto) ‚Üí str`

    **Classes de Dados Sugeridas:**

    ```python
    @dataclass
    class TagMapeada:
        """Tag com posi√ß√µes recalculadas no sistema de coordenadas original."""
        tag_id: str
        tag_nome: str
        posicao_inicio_original: int  # Posi√ß√£o no arquivo SEM tags
        posicao_fim_original: int
        clausulas: List[Dict]
        score_inferencia: float  # 1.0 (offset), 0.9-0.5 (contexto)
        metodo: str  # "offset", "contexto_completo", "contexto_parcial", "conteudo"

    @dataclass
    class ResultadoVinculacao:
        """Resultado da vincula√ß√£o com categoriza√ß√£o por confian√ßa."""
        vinculadas: List[Tuple[Dict, str, float]]  # (modificacao, clausula_id, score)
        nao_vinculadas: List[Dict]  # modificacoes sem candidatos
        revisao_manual: List[Tuple[Dict, List[Dict], float]]  # (mod, candidatos, score)

        def taxa_sucesso(self) -> float:
            total = len(self.vinculadas) + len(self.nao_vinculadas) + len(self.revisao_manual)
            return len(self.vinculadas) / total if total > 0 else 0.0

        def taxa_cobertura(self) -> float:
            """Inclui revis√£o manual como potencial sucesso."""
            total = len(self.vinculadas) + len(self.nao_vinculadas) + len(self.revisao_manual)
            cobertos = len(self.vinculadas) + len(self.revisao_manual)
            return cobertos / total if total > 0 else 0.0
    ```

### Testes

2.  **`versiona-ai/tests/test_vinculacao_formatacao.py`**

    **Testes Existentes (Manter e Adaptar):**

    - `test_vinculacao_com_formatacao_variada()` - Validar normaliza√ß√£o
    - `test_vinculacao_com_normalizacao()` - Validar estrat√©gia de normaliza√ß√£o
    - `test_vinculacao_com_mock_completo()` - Testar com mocks (adaptar para novo algoritmo)

    **Novos Testes a Criar:**

    - **`test_caminho_feliz_offset_simples()`**

      - Arquivo original id√™ntico ao arquivo COM tags (sem as tags)
      - Tags n√£o aninhadas, posi√ß√µes simples
      - **Esperado:** 100% de vincula√ß√£o, todos com score 1.0

    - **`test_caminho_feliz_offset_tags_aninhadas()`**

      - Tags aninhadas: `{{TAG-1}}...{{TAG-1.1}}...{{/TAG-1.1}}...{{/TAG-1}}`
      - Validar que offset acumulado funciona corretamente
      - **Esperado:** 100% de vincula√ß√£o, posi√ß√µes corretas mesmo com aninhamento

    - **`test_caminho_real_contexto_completo()`**

      - Arquivo original DIFERENTE do arquivo COM tags
      - Modifica√ß√µes com contexto √∫nico que permite infer√™ncia precisa
      - **Esperado:** ‚â•90% de vincula√ß√£o, scores entre 0.8-0.9

    - **`test_caminho_real_texto_ambiguo()`**

      - M√∫ltiplas cl√°usulas com texto similar
      - Contexto de vizinhan√ßa diferencia
      - **Esperado:** Vincula√ß√£o correta usando contexto, score 0.9

    - **`test_modificacao_cruzando_fronteiras()`**

      - Modifica√ß√£o que afeta duas cl√°usulas (50% em cada)
      - **Esperado:** Vinculada √† cl√°usula principal, flag `multi_clausula=True`

    - **`test_score_confianca_e_categorizacao()`**

      - Mix de modifica√ß√µes com diferentes scores
      - **Esperado:** Categoriza√ß√£o correta (vinculadas / revisao / nao_vinculadas)
      - Validar thresholds: 0.7 e 0.4

    - **`test_similaridade_threshold()`**

      - Testar com diferentes n√≠veis de similaridade: 0.96, 0.94, 0.90
      - **Esperado:** ‚â•0.95 usa Caminho Feliz, <0.95 usa Caminho Real

    - **`test_normalizacao_consistente()`**
      - Validar que normaliza√ß√£o √© aplicada igualmente em todos os pontos
      - Testar com: tabs, m√∫ltiplos espa√ßos, quebras de linha, unicode
      - **Esperado:** Resultados id√™nticos independente da formata√ß√£o

3.  **`versiona-ai/tests/test_vinculacao_performance.py`** (novo arquivo)

    - **`test_performance_100_tags_200kb()`**

      - Simular documento com 100 tags e ~200KB de texto
      - Medir tempo de execu√ß√£o
      - **Meta:** < 5 segundos sem otimiza√ß√µes, < 2 segundos com √≠ndice n-gramas

    - **`test_performance_tags_aninhadas_profundas()`**
      - Tags com 5+ n√≠veis de aninhamento
      - Validar que offset acumulado n√£o degrada performance
      - **Meta:** Tempo linear O(N), n√£o exponencial

4.  **Fixture de Teste Real** (adicionar aos testes):

    ```python
    @pytest.fixture
    def versao_real_99090886():
        """Fixture com dados reais da vers√£o 99090886."""
        return {
            "versao_id": "99090886-7f43-45c9-bfe4-ec6eddd6cde0",
            "modelo_id": "7e392c2a-9ca7-441e-8d4a-ad1a611294fa",
            "arquivo_com_tags_id": "08c0a84c-baf0-4548-8883-fa4197da7e42",
            "total_modificacoes": 55,
            "meta_minima": 50  # 90%+
        }

    def test_vinculacao_versao_real(versao_real_99090886):
        """Teste de integra√ß√£o com vers√£o real."""
        resultado = processar_versao(versao_real_99090886["versao_id"])

        vinculadas = resultado["vinculadas"]
        total = versao_real_99090886["total_modificacoes"]
        meta = versao_real_99090886["meta_minima"]

        assert len(vinculadas) >= meta, f"Esperado ‚â•{meta}, obteve {len(vinculadas)}"
        assert all(v["score"] >= 0.7 for v in vinculadas), "Todas devem ter score ‚â• 0.7"
    ```

---

## üß™ Como Testar a Solu√ß√£o

### 1. Executar Testes Unit√°rios

```bash
cd /Users/sidarta/repositorios/docx-compare/versiona-ai
python3 tests/test_vinculacao_formatacao.py
```

**Esperado:** Todos os testes (antigos e novos) devem passar.

### 2. Processar Vers√£o Real

O comando de teste permanece o mesmo, mas esperamos um resultado drasticamente melhor.

```bash
# ... (comandos para reiniciar servidor e processar vers√£o) ...

# Verificar resultado
tail -500 /tmp/flask_server.log | grep "üìã Cl√°usula vinculada" | wc -l
```

**Meta:**

- ‚úÖ Antes: 8/55 (14.5%)
- üéØ **Meta: 50+/55 (90%+)**

---

## üìä Crit√©rios de Sucesso

### M√≠nimo Aceit√°vel

- [ ] **‚â• 90% de modifica√ß√µes vinculadas** em vers√µes reais de teste (vinculadas + revis√£o manual)
- [ ] Logs claros indicando qual caminho ("Feliz" ou "Real") foi tomado para cada vers√£o
- [ ] Sistema de score de confian√ßa implementado com 3 n√≠veis (alta/m√©dia/baixa)
- [ ] Tempo de processamento ‚â§ 5 segundos para documentos de at√© 200KB
- [ ] Todos os testes unit√°rios passando (existentes + novos)
- [ ] Taxa de sucesso autom√°tico (sem revis√£o) ‚â• 70% em vers√µes reais

### Ideal

- [ ] **~100% de modifica√ß√µes v√°lidas cobertas** (vincula√ß√£o autom√°tica + revis√£o manual)
- [ ] Taxa de vincula√ß√£o autom√°tica (score ‚â• 0.7) ‚â• 85%
- [ ] Tempo de processamento < 3 segundos com otimiza√ß√µes (√≠ndice n-gramas)
- [ ] Interface web para revis√£o manual das vincula√ß√µes de m√©dia confian√ßa
- [ ] M√©tricas detalhadas por vers√£o:
  - Caminho usado (Feliz/Real)
  - Distribui√ß√£o de scores
  - Taxa de vincula√ß√£o por tipo de cl√°usula
- [ ] Documenta√ß√£o completa do algoritmo no README
- [ ] Logs estruturados (JSON) para an√°lise posterior

### M√©tricas de Valida√ß√£o

**Validar com M√∫ltiplas Vers√µes:**

1. **Vers√£o 99090886 (baseline):**

   - Antes: 8/55 (14.5%)
   - Meta: ‚â•50/55 (90%+)

2. **Vers√£o com documentos id√™nticos (Caminho Feliz):**

   - Meta: 100% com score 1.0

3. **Vers√£o com documentos divergentes (Caminho Real):**
   - Meta: ‚â•85% com score ‚â•0.7

**Regress√£o:**

- Nenhuma vers√£o que funcionava antes pode piorar

---

## üöÄ Pr√≥ximos Passos Sugeridos (Ordem de Implementa√ß√£o)

### Fase 1: Funda√ß√£o (Estimativa: 4-6 horas)

1. **Criar estruturas de dados:**

   - Classes `TagMapeada` e `ResultadoVinculacao`
   - Fun√ß√£o `normalizar_texto()` centralizada
   - ‚úÖ **Valida√ß√£o:** Testes unit√°rios simples para normaliza√ß√£o

2. **Implementar fun√ß√£o de similaridade:**

   - `_calcular_similaridade_textos()` usando `difflib.SequenceMatcher`
   - ‚úÖ **Valida√ß√£o:** Testar com pares conhecidos (id√™nticos = 1.0, diferentes = <0.9)

3. **Criar testes b√°sicos:**
   - `test_normalizacao_consistente()`
   - `test_similaridade_threshold()`
   - ‚úÖ **Valida√ß√£o:** Todos os testes passando antes de prosseguir

### Fase 2: Caminho Feliz (Estimativa: 6-8 horas)

4. **Implementar `_mapear_tags_via_offset()`:**

   - Regex para encontrar todas as tags: `r'\{\{/?[^}]+\}\}'`
   - Loop acumulando offsets
   - Recalcular posi√ß√µes das tags
   - ‚úÖ **Valida√ß√£o:** Testar com documento simples (3 tags, n√£o aninhadas)

5. **Criar testes do Caminho Feliz:**

   - `test_caminho_feliz_offset_simples()`
   - `test_caminho_feliz_offset_tags_aninhadas()`
   - ‚úÖ **Valida√ß√£o:** 100% de vincula√ß√£o nos testes

6. **Integrar no algoritmo principal:**
   - Criar `_vincular_modificacoes_clausulas_unificado()` (vers√£o inicial)
   - Implementar apenas branch do "Caminho Feliz"
   - ‚úÖ **Valida√ß√£o:** Processar vers√£o real com documentos id√™nticos

### Fase 3: Caminho Real (Estimativa: 8-12 horas)

7. **Implementar `_inferir_posicoes_via_conteudo_com_contexto()`:**

   - Extrair conte√∫do + contexto (50 chars antes/depois)
   - Busca com contexto completo ‚Üí parcial ‚Üí conte√∫do
   - Atribuir score baseado no m√©todo
   - ‚úÖ **Valida√ß√£o:** `test_caminho_real_contexto_completo()`

8. **Lidar com ambiguidade:**

   - Implementar detec√ß√£o de m√∫ltiplos candidatos
   - Usar contexto de vizinhan√ßa para desambiguar
   - ‚úÖ **Valida√ß√£o:** `test_caminho_real_texto_ambiguo()`

9. **Integrar no algoritmo principal:**
   - Adicionar branch do "Caminho Real"
   - Escolha autom√°tica baseada em similaridade (threshold 0.95)
   - ‚úÖ **Valida√ß√£o:** Processar vers√£o 99090886 (meta: ‚â•50/55)

### Fase 4: Sistema de Score e Categoriza√ß√£o (Estimativa: 4-6 horas)

10. **Implementar `_vincular_por_sobreposicao_com_score()`:**

    - Calcular score final: `tag.score √ó sobreposicao √ó fator_contexto`
    - Categorizar: alta (‚â•0.7), m√©dia (0.4-0.69), baixa (<0.4)
    - ‚úÖ **Valida√ß√£o:** `test_score_confianca_e_categorizacao()`

11. **Adicionar logs detalhados:**

    - Log de estat√≠sticas (vinculadas/revis√£o/n√£o vinculadas)
    - Log de qual caminho foi usado
    - Log de scores por modifica√ß√£o
    - ‚úÖ **Valida√ß√£o:** Verificar logs em `/tmp/flask_server.log`

12. **Implementar fila de revis√£o manual:**
    - Estrutura de dados para modifica√ß√µes pendentes
    - Endpoint API para buscar modifica√ß√µes em revis√£o (futuro)
    - ‚úÖ **Valida√ß√£o:** Verificar que modifica√ß√µes com score 0.4-0.69 v√£o para fila

### Fase 5: Casos de Borda e Otimiza√ß√£o (Estimativa: 6-8 horas)

13. **Modifica√ß√µes multi-cl√°usula:**

    - Detectar sobreposi√ß√£o ‚â•30% em m√∫ltiplas cl√°usulas
    - Vincular a array em vez de single
    - ‚úÖ **Valida√ß√£o:** `test_modificacao_cruzando_fronteiras()`

14. **Otimiza√ß√£o de performance (se necess√°rio):**

    - Implementar `_construir_indice_ngramas()` se tempo > 5 segundos
    - Paraleliza√ß√£o com `multiprocessing` se tempo > 10 segundos
    - ‚úÖ **Valida√ß√£o:** `test_performance_100_tags_200kb()` (meta: <5s)

15. **Testes de integra√ß√£o completos:**
    - `test_vinculacao_versao_real()` com fixture de produ√ß√£o
    - Validar regress√£o: vers√µes antigas n√£o podem piorar
    - ‚úÖ **Valida√ß√£o:** ‚â•90% de cobertura em m√∫ltiplas vers√µes

### Fase 6: Documenta√ß√£o e Deploy (Estimativa: 2-4 horas)

16. **Documentar algoritmo:**

    - Atualizar README com explica√ß√£o detalhada
    - Diagramas de fluxo (Caminho Feliz vs Real)
    - Exemplos de uso

17. **Deploy e valida√ß√£o:**
    - Reiniciar servidor com novo c√≥digo
    - Processar 5-10 vers√µes reais
    - Monitorar logs e taxas de sucesso
    - ‚úÖ **Crit√©rio de aceite:** ‚â•90% de cobertura (vinculadas + revis√£o)

---

**Tempo Total Estimado:** 30-44 horas (~1 semana de trabalho)

**Prioridade de Implementa√ß√£o:**

1. üî¥ **Alta:** Fases 1-3 (Funda√ß√£o + Caminhos)
2. üü° **M√©dia:** Fase 4 (Score e categoriza√ß√£o)
3. üü¢ **Baixa:** Fases 5-6 (Otimiza√ß√£o + Documenta√ß√£o)

**Estrat√©gia de Desenvolvimento:**

- ‚úÖ **TDD:** Escrever testes ANTES de implementar cada fun√ß√£o
- ‚úÖ **Incremental:** Validar cada fase antes de prosseguir
- ‚úÖ **Revers√≠vel:** Manter c√≥digo antigo comentado at√© valida√ß√£o completa

---

## üìà Estimativa de Taxa de Sucesso

Com a solu√ß√£o proposta, esperamos os seguintes resultados por cen√°rio:

| Cen√°rio                            | Descri√ß√£o                                    | Taxa de Sucesso Autom√°tico | Taxa de Cobertura Total | Observa√ß√µes                                   |
| ---------------------------------- | -------------------------------------------- | -------------------------- | ----------------------- | --------------------------------------------- |
| **Caminho Feliz**                  | Documentos id√™nticos (similaridade ‚â•95%)     | **~100%** (score 1.0)      | **100%**                | C√°lculo matem√°tico preciso via offset         |
| **Caminho Real - Alta Confian√ßa**  | Documentos diferentes mas com contexto √∫nico | **85-95%** (score 0.8-0.9) | **95-100%**             | Infer√™ncia com contexto completo funciona bem |
| **Caminho Real - M√©dia Confian√ßa** | Documentos com alguma ambiguidade            | **60-70%** (autom√°tico)    | **90-95%** (+ revis√£o)  | Alguns casos v√£o para revis√£o manual          |
| **Caminho Real - Divergente**      | Documentos muito diferentes                  | **50-60%**                 | **70-80%**              | Mais casos para revis√£o manual                |
| **M√©dia Geral (Produ√ß√£o)**         | Mix de todos os cen√°rios                     | **75-85%**                 | **90-98%**              | Depende da distribui√ß√£o de casos              |

**Legenda:**

- **Taxa de Sucesso Autom√°tico:** Vincula√ß√µes com score ‚â• 0.7 (alta confian√ßa)
- **Taxa de Cobertura Total:** Inclui revis√£o manual (score 0.4-0.69)

### Compara√ß√£o com Situa√ß√£o Atual

| M√©trica            | Antes (Atual) | Depois (Esperado) | Melhoria                 |
| ------------------ | ------------- | ----------------- | ------------------------ |
| Taxa de Vincula√ß√£o | 14.5% (8/55)  | 75-85%            | **+500% a +600%**        |
| Taxa de Cobertura  | 14.5%         | 90-98%            | **+520% a +675%**        |
| Confian√ßa          | Desconhecida  | Score 0.0-1.0     | **Sistema de qualidade** |
| Revis√£o Manual     | Inexistente   | Fila priorizada   | **Fallback robusto**     |

---

## üîç Considera√ß√µes T√©cnicas Adicionais

### 1. Normaliza√ß√£o Unicode

Importante para evitar problemas com acentos e caracteres especiais:

```python
import unicodedata

def normalizar_texto(texto):
    # Normaliza√ß√£o NFC: garante forma can√¥nica composta
    # "√©" pode ser: U+00E9 (√∫nico) OU U+0065 + U+0301 (e + acento)
    # NFC garante sempre U+00E9
    texto = unicodedata.normalize('NFC', texto)

    # Remover varia√ß√µes de espa√ßo (nbsp, thin space, etc)
    texto = re.sub(r'[\u00A0\u1680\u2000-\u200B\u202F\u205F\u3000]', ' ', texto)

    # Normalizar espa√ßos m√∫ltiplos
    texto = re.sub(r'\s+', ' ', texto)

    return texto.strip()
```

### 2. Tratamento de Tabelas e Listas

Documentos DOCX podem ter estruturas especiais:

```python
def extrair_texto_preservando_estrutura(arquivo_docx):
    """
    Extrai texto mantendo ordem l√≥gica de tabelas e listas.
    """
    doc = Document(arquivo_docx)
    texto_completo = []

    for elemento in doc.element.body:
        if elemento.tag.endswith('p'):  # Par√°grafo
            texto_completo.append(elemento.text)
        elif elemento.tag.endswith('tbl'):  # Tabela
            # Processar tabela linha por linha
            for row in elemento.findall('.//w:tr', namespaces):
                row_text = ' | '.join(cell.text for cell in row.findall('.//w:tc', namespaces))
                texto_completo.append(row_text)

    return '\n'.join(texto_completo)
```

### 3. Cache de Resultados

Para evitar reprocessamento desnecess√°rio:

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def _calcular_similaridade_cached(texto1_hash, texto2_hash, texto1, texto2):
    """Cache baseado em hash dos textos."""
    return difflib.SequenceMatcher(None, texto1, texto2).ratio()

def calcular_similaridade(texto1, texto2):
    hash1 = hashlib.md5(texto1.encode()).hexdigest()
    hash2 = hashlib.md5(texto2.encode()).hexdigest()
    return _calcular_similaridade_cached(hash1, hash2, texto1, texto2)
```

### 4. Logging Estruturado para An√°lise

```python
import json
import logging

def log_resultado_vinculacao(resultado: ResultadoVinculacao, versao_id: str, caminho: str):
    """Log estruturado em JSON para an√°lise posterior."""
    log_data = {
        "versao_id": versao_id,
        "timestamp": datetime.now().isoformat(),
        "caminho_usado": caminho,
        "metricas": {
            "total_modificacoes": len(resultado.vinculadas) + len(resultado.nao_vinculadas) + len(resultado.revisao_manual),
            "vinculadas": len(resultado.vinculadas),
            "revisao_manual": len(resultado.revisao_manual),
            "nao_vinculadas": len(resultado.nao_vinculadas),
            "taxa_sucesso": resultado.taxa_sucesso(),
            "taxa_cobertura": resultado.taxa_cobertura()
        },
        "distribuicao_scores": {
            "alta_confianca": sum(1 for _, _, s in resultado.vinculadas if s >= 0.8),
            "media_confianca": sum(1 for _, _, s in resultado.vinculadas if 0.7 <= s < 0.8),
            "baixa_confianca": len(resultado.revisao_manual)
        }
    }

    logging.info(f"RESULTADO_VINCULACAO: {json.dumps(log_data)}")
```

### 5. Detec√ß√£o de Anomalias

Alertar quando resultados parecem incorretos:

```python
def validar_resultado(resultado: ResultadoVinculacao, tags_totais: int):
    """Valida√ß√£o de sanidade dos resultados."""
    warnings = []

    # Anomalia 1: Taxa de sucesso muito baixa
    if resultado.taxa_sucesso() < 0.30:
        warnings.append(f"‚ö†Ô∏è  Taxa de sucesso muito baixa: {resultado.taxa_sucesso():.1%}")

    # Anomalia 2: Muitas modifica√ß√µes sem vincula√ß√£o
    if len(resultado.nao_vinculadas) > len(resultado.vinculadas):
        warnings.append(f"‚ö†Ô∏è  Mais n√£o vinculadas ({len(resultado.nao_vinculadas)}) do que vinculadas ({len(resultado.vinculadas)})")

    # Anomalia 3: Nenhuma vincula√ß√£o com alta confian√ßa
    alta_confianca = sum(1 for _, _, s in resultado.vinculadas if s >= 0.9)
    if alta_confianca == 0 and len(resultado.vinculadas) > 10:
        warnings.append(f"‚ö†Ô∏è  Nenhuma vincula√ß√£o com alta confian√ßa (score ‚â• 0.9)")

    if warnings:
        for w in warnings:
            print(w)
        print("üîç Considere revisar a qualidade dos dados de entrada.")

    return len(warnings) == 0
```

---

## üè∑Ô∏è Tags

`#vincula√ß√£o` `#cl√°usulas` `#tags` `#modifica√ß√µes` `#solu√ß√£o-refinada` `#high-priority` `#coordenadas` `#offset` `#inferencia` `#algoritmo-unificado` `#score-confianca` `#revisao-manual` `#performance`

---

## üìö Refer√™ncias e Recursos

### Documenta√ß√£o Relacionada

- **Task 001:** Agrupamento posicional de modifica√ß√µes (‚úÖ completa)
- **Task 002:** Integra√ß√£o do processamento de tags (‚úÖ completa)
- **Testes Unit√°rios:** `/versiona-ai/tests/test_vinculacao_formatacao.py`
- **Servidor Flask:** `/versiona-ai/directus_server.py` (linhas 240-920)

### APIs e Bibliotecas Utilizadas

- **Directus API:** https://contract.devix.co

  - Token: `S1okNXYabq9TL1gVj0TxiNEdu0md_F3d` (permiss√µes limitadas)
  - Documenta√ß√£o: https://directus.io/docs/guides/ai/mcp

- **Python difflib:** Para c√°lculo de similaridade

  - `difflib.SequenceMatcher(None, texto1, texto2).ratio()`
  - Documenta√ß√£o: https://docs.python.org/3/library/difflib.html

- **Python re (regex):** Para processamento de tags
  - Pattern: `r'\{\{/?[^}]+\}\}'` (tags aninhadas)
  - Documenta√ß√£o: https://docs.python.org/3/library/re.html

### Algoritmos e Conceitos

1. **Longest Common Subsequence (LCS):**

   - Usado para inferir posi√ß√µes quando documentos divergem
   - Complexidade: O(n√óm) no pior caso
   - Otimiza√ß√£o: √çndice de n-gramas reduz para O(n) amortizado

2. **Offset Acumulado:**

   - T√©cnica para mapear coordenadas entre documentos com inser√ß√µes
   - Similar ao usado em diffs (unified diff format)
   - Complexidade: O(N log N) por ordena√ß√£o

3. **Score de Confian√ßa (Confidence Score):**
   - T√©cnica comum em ML/NLP para quantificar incerteza
   - Permite decis√µes baseadas em threshold
   - Implementa√ß√£o: produto ponderado de m√∫ltiplos fatores

### Ferramentas de Desenvolvimento

- **VS Code:** Editor principal
- **Python 3.13:** Runtime
- **pytest:** Framework de testes
- **uv:** Gerenciador de depend√™ncias
- **Flask:** Framework web (servidor API)

### Dados de Teste

**Vers√£o Real Principal:** `99090886-7f43-45c9-bfe4-ec6eddd6cde0`

- Contrato: `77b8555b-e40d-4ece-8c8a-88367b36a625`
- Modelo: `7e392c2a-9ca7-441e-8d4a-ad1a611294fa` (Minuta de empreitada)
- Arquivo COM Tags: `08c0a84c-baf0-4548-8883-fa4197da7e42`
- Total modifica√ß√µes: 55
- Resultado atual: 8/55 (14.5%)
- Meta: ‚â•50/55 (90%+)

### Logs e Monitoramento

- **Servidor:** `localhost:8001`
- **Logs:** `/tmp/flask_server.log`
- **Health Check:** `curl http://localhost:8001/health`
- **Processar Vers√£o:** `curl -X POST http://localhost:8001/api/process -H "Content-Type: application/json" -d '{"versao_id": "..."}'`

### Comandos √öteis

```bash
# Reiniciar servidor
cd /Users/sidarta/repositorios/docx-compare
lsof -ti:8001 | xargs kill -9 2>/dev/null
cd versiona-ai
nohup python3 directus_server.py > /tmp/flask_server.log 2>&1 &

# Verificar taxa de vincula√ß√£o
tail -500 /tmp/flask_server.log | grep "üìã Cl√°usula vinculada" | wc -l

# Executar testes
cd versiona-ai
python3 tests/test_vinculacao_formatacao.py

# Executar testes com pytest
uv run pytest tests/ -v

# Verificar erros
tail -100 /tmp/flask_server.log | grep -E "(ERROR|Exception)"
```

---

**√öltima Atualiza√ß√£o:** 2025-10-11 21:30
**Vers√£o do Documento:** 2.0 (Refinado com otimiza√ß√µes e casos de borda)
**Pr√≥xima Revis√£o:** Ap√≥s implementa√ß√£o das Fases 1-3 (Funda√ß√£o + Caminhos)

---

## ‚úÖ Checklist de Implementa√ß√£o

### Fase 1: Funda√ß√£o ‚¨ú (0/3)

- [ ] Criar estruturas de dados (TagMapeada, ResultadoVinculacao)
- [ ] Implementar fun√ß√£o centralizada de normaliza√ß√£o
- [ ] Implementar fun√ß√£o de c√°lculo de similaridade

### Fase 2: Caminho Feliz ‚¨ú (0/3)

- [ ] Implementar `_mapear_tags_via_offset()`
- [ ] Criar testes para Caminho Feliz (simples + aninhado)
- [ ] Integrar branch "Caminho Feliz" no algoritmo principal

### Fase 3: Caminho Real ‚¨ú (0/3)

- [ ] Implementar `_inferir_posicoes_via_conteudo_com_contexto()`
- [ ] Criar testes para Caminho Real (contexto + ambiguidade)
- [ ] Integrar branch "Caminho Real" no algoritmo principal

### Fase 4: Score e Categoriza√ß√£o ‚¨ú (0/3)

- [ ] Implementar `_vincular_por_sobreposicao_com_score()`
- [ ] Adicionar logs detalhados e estruturados
- [ ] Implementar fila de revis√£o manual

### Fase 5: Robustez ‚¨ú (0/3)

- [ ] Implementar detec√ß√£o de modifica√ß√µes multi-cl√°usula
- [ ] Otimizar performance (√≠ndice n-gramas se necess√°rio)
- [ ] Criar testes de integra√ß√£o com dados reais

### Fase 6: Finaliza√ß√£o ‚¨ú (0/2)

- [ ] Documentar algoritmo no README
- [ ] Deploy e valida√ß√£o em produ√ß√£o (‚â•90% cobertura)

---

**Progresso Geral:** 0/17 tarefas (0%)

**Meta de Sucesso:**

- ‚úÖ Antes: 8/55 (14.5%)
- üéØ **Meta: ‚â•50/55 (90%+)**

---

## üìù Notas de Implementa√ß√£o

_Esta se√ß√£o deve ser preenchida durante a implementa√ß√£o com observa√ß√µes importantes, decis√µes t√©cnicas e aprendizados._

### Decis√µes T√©cnicas

- [ ] Threshold de similaridade definido: **\_**%
- [ ] Tamanho do contexto de vizinhan√ßa: **\_** caracteres
- [ ] Scores de confian√ßa calibrados: alta (\_**\_), m√©dia (\_\_**), baixa (\_\_\_\_)
- [ ] Performance aceit√°vel alcan√ßada: **\_** segundos para **\_** KB

### Problemas Encontrados

_Documentar problemas inesperados e suas solu√ß√µes aqui._

### Melhorias Futuras

_Ideias para otimiza√ß√£o ou features adicionais identificadas durante a implementa√ß√£o._
